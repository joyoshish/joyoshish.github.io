<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> k-means++ অ্যালগরিদম | Joyoshish Saha </title> <meta name="author" content="Joyoshish Saha"> <meta name="description" content="k-means++ অ্যালগরিদম"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E0%A6%9C&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://joyoshish.github.io/blog/2024/kmeansplusplus_beng/"> <script src="/assets/js/theme.js?a5ca4084d3b81624bcfa01156dae2b8e"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <div class="navbar-brand social"> <a href="mailto:%6A%6F%79%6F%73%68%69%73%68@%70%72%6F%74%6F%6E%6D%61%69%6C.%63%6F%6D" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://www.linkedin.com/in/joyoshishsaha" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-linkedin"></i></a> <a href="https://facebook.com/joyoshish" title="Facebook" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-facebook"></i></a> </div> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Joyoshish</span> Saha </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">Home </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">Résumé </a> </li> <li class="nav-item "> <a class="nav-link" href="/blogging/index.html">Blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/reserach/">Research </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Resources </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/acadresrc/">Computer Science and Data Science</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/rndmresrc/">Random</a> </div> </li> <li class="nav-item "> <a class="nav-link" href="/gallery/">Gallery </a> </li> <li class="nav-item "> <a class="nav-link" href="/contact/">Contact </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">k-means++ অ্যালগরিদম</h1> <p class="post-meta"> May 05, 2024 </p> <p class="post-tags"> <a href="/blog/2024"> <i class="fa-solid fa-calendar fa-sm"></i> 2024 </a>   ·   <a href="/blog/tag/ml"> <i class="fa-solid fa-hashtag fa-sm"></i> ml</a>   <a href="/blog/tag/ai"> <i class="fa-solid fa-hashtag fa-sm"></i> ai</a>     ·   <a href="/blog/category/machine-learning"> <i class="fa-solid fa-tag fa-sm"></i> machine-learning</a>   </p> </header> <article class="post-content"> <div id="markdown-content"> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/kmpp-480.webp 480w,/assets/img/kmpp-800.webp 800w,/assets/img/kmpp-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/kmpp.gif" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Unlucky choices! (Source: http://shabal.in/visuals.html) </div> <p>k-means++ clustering ব্যাবহার করে আমরা বেশিরভাগ unsupervised learning এর ক্ষেত্রে k-means clustering এর তুলনায় বেশি দ্রুত এবং অধিকতর নিকট সমাধান পেতে পারি। যেহেতু unsupervised learning এর ক্ষেত্রে কোনও সুনির্দিষ্ট সমাধান থাকে না, তাই যেকোনো unsupervised learning এই আমরা চেষ্টা করি cost কমানোর যেটি k-means++ খুবই দক্ষতার সাথে করে।</p> <p>David Arthur এবং Sergei Vassilvitskii ২০০৭ সালে k-means++ অ্যালগরিদমটির প্রস্তাব দেন standard k-means থেকে clustering এর NP-hard সমাধান হিসাবে।</p> <h3 id="standard-k-means-algorithm-এর-অপূর্ণতা">Standard k-means algorithm এর অপূর্ণতা</h3> <p>k-means++ শেখার আগে আমাদের জেনে নেওয়া ভাল standard k-means algorithm এর ত্রুটি এবং এর অপূর্ণতাগুলি।</p> <p>১/ কিছু ক্ষেত্রে k-means বহুবার iterated হয় যা algorithm টাকে ধীর করে দেয়।</p> <p>২/ k-means কেমন কাজ করবে তা বেশিরভাগটাই নির্ভর করে আমরা প্রাথমিক ভাবে যে cluster center গুলো এলোমেলোভাবে নির্বাচন করেছি তার উপর। এটির কারণেই কখনো কখনো k-means একই cluster এ দুটি cluster center নির্বাচন করে ফেলে। এটি উপযুক্ত উদাহরণ দিয়ে বোঝা যাক।</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/kmpp1.webp-480.webp 480w,/assets/img/kmpp1.webp-800.webp 800w,/assets/img/kmpp1.webp-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/kmpp1.webp" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>এক্ষেত্রে ‘a’ cluster এ বাস্তবে 2 টি cluster থাকলেও k-means তা নির্ধারণ করতে অক্ষম। একইসাথে এটি ‘c’ ও ‘d’ cluster কে আলাদা বললেও তা আসলে একটিই cluster। এভাবেই k-means কখনো কখনো local optimum এই সীমাবদ্ধ থেকে যায় এবং তা bad cluster সৃষ্টি করে।</p> <h3 id="k-means-algorithm">k-means++ algorithm</h3> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/kmpp2.webp-480.webp 480w,/assets/img/kmpp2.webp-800.webp 800w,/assets/img/kmpp2.webp-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/kmpp2.webp" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>এবার আসা যাক k-means++ algorithm এ এবং এটি কেমন কার্যকরী ভাবে clustering করে।</p> <p>কোনো data set থেকে আমরা নিম্নোক্ত উপায়ে clustering করতে পারি।</p> <p>১ক/ প্রথমেই আমরা randomly একটি cluster center নির্ধারণ করি data set থেকে। (uniform and random choice)</p> <p>১খ/ এখন data set এর থেকে পরবর্তী center টি নির্ধারণ করতে আমরা furthest point strategy ব্যাবহার করি।</p> <p>এই পদ্ধতিতে আমরা কোনো point কে তখনি একটি cluster center নির্বাচন করি যখন সেটি পূর্ব নির্ধারিত cluster center থেকে সবথেকে বেশি দুরে অবস্থান করে।</p> <p>এটি গাণিতিকভাবে নির্ণয় করতে আমরা একটি নতুন চল ধরব D(x) যা হল কোনো data point থেকে ইতিমধ্যে নির্বাচিত cluster center গুলোর দূরত্ব গুলোর মধ্যে নিম্নতমটি (min c∈C abs(x − c))। এখন পরবর্তী cluster center নির্ধারণ করার সময় আমরা data point গুলোর মধ্যে সেটিকে নির্বাচন করব যার ক্ষেত্রে D(x)²/ΣD(x)² এই সম্ভাবনা টা বেশি। (furthest point strategy)</p> <p>নীচে একটি উদাহারণ দিলে বিষয়টি আরও পরিষ্কার হয়ে যাবে। (ক্রমশ)</p> <p>২/ আমরা এই ভাবে cluster center নির্বাচন করব যতক্ষণ আমাদের কাছে k টি cluster center আসে।</p> <p>৩/ এভাবে cluster center initialisation এর পর আমরা প্রত্যেক data point কে তার নিকটতম cluster center এর সংশ্লিষ্ট cluster এ অন্তর্ভুক্ত করবো, যেমন ভাবে আমরা k-means algorithm এ করে থাকি।</p> <p>আমরা এই data points allocation ততক্ষণ করবো যতক্ষণ না cluster center গুলো অপরিবর্তিত থাকছে।</p> <h3 id="উদাহরণ">উদাহরণ</h3> <p>এবার একটি 1 dimensional data points নিয়ে k-means++ algorithm টি ঝালিয়ে নেওয়া যাক।</p> <p>ধরা যাক আমাদের কাছে data points আছে {0, 1, 2, 5, 6} এবং আমরা ২ টি cluster এই data points থেকে পেতে চাই। (k = 2)</p> <p>প্রথম cluster center C1 হল 0। C1 = 0 (প্রথম cluster center টি আমরা অনির্দিষ্ট ভাবে প্রথম data point টাকে নেব)</p> <p>এখন দ্বিতীয় cluster center নির্বাচনের ক্ষেত্রে আমরা D(x)²/ΣD(x)² এই সম্ভাবনা টা প্রতিটি data point এর জন্য নির্ণয় করবো।</p> <p>P(C2=1) = ((1–0)²)f = 1f নিকটতম cluster center, C1=0</p> <p>P(C2=2) = ((2–0)²)f = 4f নিকটতম cluster center, C1=0</p> <p>P(C2=5) = ((5–0)²)f = 25f নিকটতম cluster center, C1=0</p> <p>P(C2=6) = ((6–0)²)f = 36f নিকটতম cluster center, C1=0</p> <p>এখানে f = (1+4+25+36)</p> <p>দেখা যাচ্ছে P(C2=6) সবথেকে বেশি, তাই k-means++ 6 কে C2 হিসাবে নির্বাচন করবে। C2 = 6</p> <p>এরপর আমরা data point গুলোকে সবথেকে কাছের সংশ্লিষ্ট cluster center এর সাথে যুক্ত করলেই দুটি cluster পেয়ে যাব {(0, 1, 2)(5, 6)} ।</p> <p>অন্য একটি উদাহরণ নিয়ে দেখা যাক।</p> <p>ধরা যাক আমাদের কাছে data points আছে</p> <p>{0, 1, 2, 5, 6, 9, 10} এবং আমরা ৩ টি cluster এই data points থেকে পেতে চাই। (k = 3)</p> <p>প্রথম cluster center C1 হল 0। C1 = 0</p> <p>দ্বিতীয় cluster center নির্বাচনের ক্ষেত্রে প্রথম উদাহরণের মতই আমরা furthest point 10 কে C2 হিসাবে নির্বাচন করবো। C2 = 10</p> <p>এখন তৃতীয় cluster center এর জন্য আমাদেরকে সংশ্লিষ্ট সম্ভাবনা গুলো নির্ণয় করতে হবে প্রতিটি data point এর জন্য।</p> <p>P(C3=1) = ((1–0)²)f = 1f নিকটতম cluster center, C1=0</p> <p>P(C3=2) = ((2–0)²)f = 4f নিকটতম cluster center, C1=0</p> <p>P(C3=5) = ((5–0)²)f = 25f নিকটতম cluster center, C1=0</p> <p>P(C3=6) = ((6–10)²)f = 16f নিকটতম cluster center, C2=10</p> <p>P(C3=9) = ((9–10)²)f = 1f নিকটতম cluster center, C2=10</p> <p>এখানে f = (1+4+25+16+1)</p> <p>দেখা যাচ্ছে P(C3=5) সবথেকে বেশি, তাই k-means++ 5 কে C3 হিসাবে নির্বাচন করবে। C3 = 5</p> <p>এরপর আমরা data point গুলোকে সবথেকে কাছের সংশ্লিষ্ট cluster center এর সাথে সংযুক্ত করলেই তিনটি cluster পেয়ে যাব। {(0, 1, 2)(5, 6)(9, 10)}</p> <p>এভাবেই 2 dimensional বা উচ্চতর dimension এ আমরা k-means++ ব্যাবহার করে clustering করতে পারি। তথ্যগতভাবে বলা যেতে পারে k-means এবং k-means++ এর মধ্যে cluster center initialisation এরই শুধু পার্থক্য রয়েছে, বাকি প্রক্রিয়া দুক্ষেত্রেই এক।</p> <h3 id="k-means-algorithm-এর-কার্যকারিতা">k-means++ algorithm এর কার্যকারিতা</h3> <p>এখন k-means algorithm এর থেকে k-means++ কতটা কার্যকর তা দেখা যাক।</p> <p>এখানে একটি dataset এর scatter plot দেওয়া হল</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/kmpp3.webp-480.webp 480w,/assets/img/kmpp3.webp-800.webp 800w,/assets/img/kmpp3.webp-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/kmpp3.webp" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>এবার k-means এবং k-means++ এর জন্য cluster center initialisation এর 2 dimensional histogram দেখা যাক</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/kmpp4.webp-480.webp 480w,/assets/img/kmpp4.webp-800.webp 800w,/assets/img/kmpp4.webp-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/kmpp4.webp" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>এর থেকে পরিষ্কার ভাবে বোঝা যায় k-means++ cluster গুলোর মধ্যভাগে বেশি initialise করেছে যা বেশিরভাগ dataset এর জন্য দ্রুত হবে এবং অধিকতর সঠিক cluster বানাতে সক্ষম হবে।</p> <h3 id="k-means-এর-অপূর্ণতা">k-means++ এর অপূর্ণতা</h3> <p>K-means++ সম্পর্কে আলোচনা শেষ করার পূর্বে এটির কিছু ত্রুটি দেখে নেওয়া দরকার যা বাস্তব data set গুলোতে ব্যাবহারের ক্ষেত্রে দেখা দিতে পারে।</p> <p>১/ k-means++ বিচ্ছিন্ন data point এর ক্ষেত্রে খুবই সংবেদনশীল (sensitive to outliers)। কারণ k-means++ সবসময় furthest point strategy ব্যাবহার করে cluster center গুলো নির্বাচন করে, যা করতে গিয়ে কিছুক্ষেত্রে তা বিচ্ছিন্ন একটি point কে cluster center নির্বাচন করে ফেলে যা কোন cluster সৃষ্টি করতে তেমন কোন গুরুত্ব রাখে না।</p> <p>২/ ধরা যাক কোন Game Developer Company তাদের game খেলে, এমন যত gamer আছে, তাদের পছন্দের game genre(List of video game genres — Wikipedia) গুলো দিয়ে clustering করতে আগ্রহী। এখন game genre এর সংখ্যা অনেক বেশি হওয়ায় k-means++ cluster center initialisation এর জন্য ঠিক ততবারই data point গুলোর মধ্যে algorithm টিকে pass করাবে। সেক্ষেত্রে প্রক্রিয়াটি মন্থর হয়ে যাবে। k-means++ k সংখ্যক বার data point pass করার জন্য যেখানে k একটি অনেক বড় সংখ্যা তখন দ্রুত কাজ করে না। এটি অতিক্রম করতে আমরা oversampling এর সাহায্য নিই এবং এর থেকে k-means এর অন্য একটি ভিন্নতা — parallel k-means এর উৎপত্তি (<a href="http://theory.stanford.edu/~sergei/papers/vldb12-kmpar.pdf" rel="external nofollow noopener" target="_blank">http://theory.stanford.edu/~sergei/papers/vldb12-kmpar.pdf</a>)।</p> <p>এসব সত্ত্বেও বেশিরভাগ data set এর জন্য k-means++ তথাকথিত k-means algorithm এর থেকে বেশি সফল ভাবে clustering করতে সক্ষম।</p> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © <a href="https://joyoshish.github.io/">Joyoshish Saha</a> </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?b7816bd189846d29eded8745f9c4cf77"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id="></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script type="text/javascript" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"> </script> </body> </html>